{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47aa8108",
   "metadata": {},
   "source": [
    "# ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "236ea524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import unicodedata\n",
    "from keras import layers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e3e9ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3725\n"
     ]
    }
   ],
   "source": [
    "# Open and read a txt file\n",
    "with open('dialogs.txt', 'r') as file:\n",
    " train = [line.rstrip() for line in file]\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dd64b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"hi, how are you doing?\\ti'm fine. how about yourself?\",\n",
       " \"i'm fine. how about yourself?\\ti'm pretty good. thanks for asking.\",\n",
       " \"i'm pretty good. thanks for asking.\\tno problem. so how have you been?\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7edca72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Separator = '\\t'\n",
    "train_input, train_target = map(list,zip(*[pair.split(Separator) for pair in train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42fcd4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi, how are you doing?', \"i'm fine. how about yourself?\", \"i'm pretty good. thanks for asking.\"]\n",
      "[\"i'm fine. how about yourself?\", \"i'm pretty good. thanks for asking.\", 'no problem. so how have you been?']\n"
     ]
    }
   ],
   "source": [
    "print(train_input[:3])\n",
    "print(train_target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecb6b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(s):\n",
    "  s = re.sub(r\"([?.!,Â¿])\", r\" \\1 \", s)\n",
    "  s = re.sub(r'[\" \"]+', \" \", s)\n",
    "  s = s.strip()\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1aa440c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi , how are you doing ?', \"i'm fine . how about yourself ?\", \"i'm pretty good . thanks for asking .\"]\n"
     ]
    }
   ],
   "source": [
    "train_preprocessed_input = [preprocess_sentence(s) for s in train_input]\n",
    "train_preprocessed_target = [preprocess_sentence(s) for s in train_target]\n",
    "\n",
    "print(train_preprocessed_input[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61c36e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<sos> i'm fine . how about yourself ? <eos>\",\n",
       " \"<sos> i'm pretty good . thanks for asking . <eos>\",\n",
       " '<sos> no problem . so how have you been ? <eos>']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tag_target_sentences(sentences):\n",
    "  tagged_sentences = map(lambda s: (' ').join(['<sos>', s, '<eos>']), sentences)\n",
    "  return list(tagged_sentences)\n",
    "\n",
    "train_tagged_preprocessed_target = tag_target_sentences(train_preprocessed_target)\n",
    "\n",
    "train_tagged_preprocessed_target[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95a14e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<unk>', filters='\"#$%&()*+-/:;=@[\\\\]^_`{|}~\\t\\n')\n",
    "source_tokenizer.fit_on_texts(train_preprocessed_input)\n",
    "# source_tokenizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a04d478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2397\n"
     ]
    }
   ],
   "source": [
    "source_vocab_size = len(source_tokenizer.word_index) + 1\n",
    "print(source_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2eda2415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer for the English target sentences.\n",
    "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<unk>', filters='\"#$%&()*+-/:;=@[\\\\]^_`{|}~\\t\\n')\n",
    "target_tokenizer.fit_on_texts(train_tagged_preprocessed_target)\n",
    "# target_tokenizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "765717cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2461\n"
     ]
    }
   ],
   "source": [
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
    "print(target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "602bc788",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoder_inputs = source_tokenizer.texts_to_sequences(train_preprocessed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92f624e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1016, 6, 40, 18, 5, 160, 3], [29, 640, 2, 40, 37, 548, 3], [29, 152, 48, 2, 290, 28, 486, 2]]\n",
      "['hi , how are you doing ?', \"i'm fine . how about yourself ?\", \"i'm pretty good . thanks for asking .\"]\n"
     ]
    }
   ],
   "source": [
    "print(train_encoder_inputs[:3])\n",
    "print(source_tokenizer.sequences_to_texts(train_encoder_inputs[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c559136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_decoder_inputs_targets(sentences, tokenizer):\n",
    "  seqs = tokenizer.texts_to_sequences(sentences)\n",
    "  decoder_inputs = [s[:-1] for s in seqs] # Drop the last token in the sentence.\n",
    "  decoder_targets = [s[1:] for s in seqs] # Drop the first token in the sentence.\n",
    "  # Example [\"<sos> i'm fine . how about yourself ?\"] [\"i'm fine . how about yourself ? <eos>\"]\n",
    "  return decoder_inputs, decoder_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b83af39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 38, 561, 4, 44, 39, 562, 6] \n",
      " [38, 561, 4, 44, 39, 562, 6, 3]\n"
     ]
    }
   ],
   "source": [
    "train_decoder_inputs, train_decoder_targets = generate_decoder_inputs_targets(train_tagged_preprocessed_target,target_tokenizer)\n",
    "\n",
    "print(train_decoder_inputs[0],'\\n', train_decoder_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce3166a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"<sos> i'm fine . how about yourself ?\"] [\"i'm fine . how about yourself ? <eos>\"]\n"
     ]
    }
   ],
   "source": [
    "print(target_tokenizer.sequences_to_texts(train_decoder_inputs[:1]),\n",
    "      target_tokenizer.sequences_to_texts(train_decoder_targets[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36463676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_encoding_len = len(max(train_encoder_inputs, key=len))\n",
    "max_encoding_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e488f1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_decoding_len = len(max(train_decoder_inputs, key=len))\n",
    "max_decoding_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2dab669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1016    6   40   18    5  160    3    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "[  2  38 561   4  44  39 562   6   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0]\n",
      "[ 38 561   4  44  39 562   6   3   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "padded_train_encoder_inputs = pad_sequences(train_encoder_inputs, max_encoding_len, padding='post', truncating='post')\n",
    "padded_train_decoder_inputs = pad_sequences(train_decoder_inputs, max_decoding_len, padding='post', truncating='post')\n",
    "padded_train_decoder_targets = pad_sequences(train_decoder_targets, max_decoding_len, padding='post', truncating='post')\n",
    "\n",
    "print(padded_train_encoder_inputs[0])\n",
    "print(padded_train_decoder_inputs[0])\n",
    "print(padded_train_decoder_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4aeeef58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<sos> i'm fine . how about yourself ? <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tokenizer.sequences_to_texts([padded_train_decoder_inputs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "321e5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dialogs.txt', 'r') as file:\n",
    "    data = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93a78b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2980 745\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# spliting the data into train and test\n",
    "random.shuffle(data)\n",
    "train_size = int(0.8 * len(data))\n",
    "train = data[:train_size]\n",
    "val = data[train_size:]\n",
    "print(len(train), len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdb0f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset):\n",
    "\n",
    "  # Split the Hungarian and English sentences into separate lists.\n",
    "  input, output = map(list, zip(*[pair.split(Separator) for pair in dataset]))\n",
    "\n",
    "  # Unicode normalization and inserting spaces around punctuation.\n",
    "  preprocessed_input = [preprocess_sentence(s) for s in input]\n",
    "  preprocessed_output = [preprocess_sentence(s) for s in output]\n",
    "\n",
    "  # Tag target sentences with <sos> and <eos> tokens.\n",
    "  tagged_preprocessed_output = tag_target_sentences(preprocessed_output)\n",
    "\n",
    "  # Vectorize encoder source sentences.\n",
    "  encoder_inputs = source_tokenizer.texts_to_sequences(preprocessed_input)\n",
    "\n",
    "  # Vectorize and create decoder input and target sentences.\n",
    "  decoder_inputs, decoder_targets = generate_decoder_inputs_targets(tagged_preprocessed_output,\n",
    "                                                                    target_tokenizer)\n",
    "\n",
    "  # Pad all collections.\n",
    "  padded_encoder_inputs = pad_sequences(encoder_inputs, max_encoding_len, padding='post', truncating='post')\n",
    "  padded_decoder_inputs = pad_sequences(decoder_inputs, max_decoding_len, padding='post', truncating='post')\n",
    "  padded_decoder_targets = pad_sequences(decoder_targets, max_decoding_len, padding='post', truncating='post')\n",
    "\n",
    "  return padded_encoder_inputs, padded_decoder_inputs, padded_decoder_targets\n",
    "\n",
    "# Process validation dataset\n",
    "padded_val_encoder_inputs, padded_val_decoder_inputs, padded_val_decoder_targets = process_dataset(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c37d0c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââââââââââââ³ââââââââââââââââââââââââââââ³ââââââââââââââââââ³âââââââââââââââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)                  </span>â<span style=\"font-weight: bold\"> Output Shape              </span>â<span style=\"font-weight: bold\">         Param # </span>â<span style=\"font-weight: bold\"> Connected to               </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                          â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                          â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)             â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â masking_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)           â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â         <span style=\"color: #00af00; text-decoration-color: #00af00\">306,816</span> â masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â         <span style=\"color: #00af00; text-decoration-color: #00af00\">315,008</span> â masking_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      â         <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> â embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â\n",
       "â                               â <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]        â                 â                            â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 â [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),       â         <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> â embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         â\n",
       "â                               â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)] â                 â lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2461</span>)        â         <span style=\"color: #00af00; text-decoration-color: #00af00\">632,477</span> â lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               â\n",
       "âââââââââââââââââââââââââââââââââ´ââââââââââââââââââââââââââââ´ââââââââââââââââââ´âââââââââââââââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââââââââââââ³ââââââââââââââââââââââââââââ³ââââââââââââââââââ³âââââââââââââââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â               \u001b[38;5;34m0\u001b[0m â -                          â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â               \u001b[38;5;34m0\u001b[0m â -                          â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â masking (\u001b[38;5;33mMasking\u001b[0m)             â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â               \u001b[38;5;34m0\u001b[0m â input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â masking_1 (\u001b[38;5;33mMasking\u001b[0m)           â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â               \u001b[38;5;34m0\u001b[0m â input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â embedding (\u001b[38;5;33mEmbedding\u001b[0m)         â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â         \u001b[38;5;34m306,816\u001b[0m â masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)       â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â         \u001b[38;5;34m315,008\u001b[0m â masking_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â lstm (\u001b[38;5;33mLSTM\u001b[0m)                   â [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      â         \u001b[38;5;34m394,240\u001b[0m â embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â\n",
       "â                               â \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]        â                 â                            â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                 â [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),       â         \u001b[38;5;34m394,240\u001b[0m â embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         â\n",
       "â                               â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)] â                 â lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     â\n",
       "âââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââ¼ââââââââââââââââââ¼âââââââââââââââââââââââââââââ¤\n",
       "â dense (\u001b[38;5;33mDense\u001b[0m)                 â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2461\u001b[0m)        â         \u001b[38;5;34m632,477\u001b[0m â lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               â\n",
       "âââââââââââââââââââââââââââââââââ´ââââââââââââââââââââââââââââ´ââââââââââââââââââ´âââââââââââââââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,042,781</span> (7.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,042,781\u001b[0m (7.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,042,781</span> (7.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,042,781\u001b[0m (7.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "default_dropout=0.2\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Encoder model with Masking\n",
    "encoder_inputs = tf.keras.Input(shape=(None,))\n",
    "\n",
    "encoder_masking = layers.Masking(mask_value=0.0)(encoder_inputs)\n",
    "\n",
    "encoder_embedding = layers.Embedding(input_dim=source_vocab_size, output_dim=embedding_dim)(encoder_masking)\n",
    "\n",
    "encoder_lstm = layers.LSTM(hidden_dim, return_state=True)\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "encoder_model = tf.keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder model with Masking\n",
    "decoder_inputs = tf.keras.Input(shape=(None,))\n",
    "\n",
    "decoder_masking = layers.Masking(mask_value=0.0)(decoder_inputs)\n",
    "\n",
    "decoder_embedding = layers.Embedding(input_dim=target_vocab_size, output_dim=embedding_dim)(decoder_masking)\n",
    "\n",
    "decoder_lstm = layers.LSTM(hidden_dim, return_sequences=True, return_state=True)\n",
    "\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = layers.Dense(target_vocab_size, activation='softmax')\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Full model\n",
    "model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60e48bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 153ms/step - accuracy: 0.5988 - loss: 3.7120 - val_accuracy: 0.6769 - val_loss: 1.9754\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 143ms/step - accuracy: 0.6978 - loss: 1.9216 - val_accuracy: 0.6999 - val_loss: 1.8563\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 142ms/step - accuracy: 0.7077 - loss: 1.8120 - val_accuracy: 0.7011 - val_loss: 1.7945\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.7081 - loss: 1.7639 - val_accuracy: 0.7045 - val_loss: 1.7490\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 143ms/step - accuracy: 0.7084 - loss: 1.7318 - val_accuracy: 0.7069 - val_loss: 1.7073\n",
      "Epoch 6/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.7134 - loss: 1.6805 - val_accuracy: 0.7130 - val_loss: 1.6608\n",
      "Epoch 7/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 143ms/step - accuracy: 0.7161 - loss: 1.6580 - val_accuracy: 0.7177 - val_loss: 1.6085\n",
      "Epoch 8/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.7231 - loss: 1.5925 - val_accuracy: 0.7230 - val_loss: 1.5577\n",
      "Epoch 9/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.7284 - loss: 1.5471 - val_accuracy: 0.7288 - val_loss: 1.5131\n",
      "Epoch 10/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 142ms/step - accuracy: 0.7353 - loss: 1.4852 - val_accuracy: 0.7338 - val_loss: 1.4698\n",
      "Epoch 11/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 143ms/step - accuracy: 0.7370 - loss: 1.4643 - val_accuracy: 0.7364 - val_loss: 1.4307\n",
      "Epoch 12/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 154ms/step - accuracy: 0.7409 - loss: 1.4210 - val_accuracy: 0.7392 - val_loss: 1.3930\n",
      "Epoch 13/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 160ms/step - accuracy: 0.7436 - loss: 1.3829 - val_accuracy: 0.7423 - val_loss: 1.3577\n",
      "Epoch 14/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.7470 - loss: 1.3422 - val_accuracy: 0.7434 - val_loss: 1.3266\n",
      "Epoch 15/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 156ms/step - accuracy: 0.7472 - loss: 1.3226 - val_accuracy: 0.7461 - val_loss: 1.2956\n",
      "Epoch 16/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.7473 - loss: 1.2942 - val_accuracy: 0.7464 - val_loss: 1.2632\n",
      "Epoch 17/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.7494 - loss: 1.2658 - val_accuracy: 0.7506 - val_loss: 1.2344\n",
      "Epoch 18/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 151ms/step - accuracy: 0.7527 - loss: 1.2301 - val_accuracy: 0.7552 - val_loss: 1.2018\n",
      "Epoch 19/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 146ms/step - accuracy: 0.7540 - loss: 1.2040 - val_accuracy: 0.7568 - val_loss: 1.1780\n",
      "Epoch 20/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.7601 - loss: 1.1641 - val_accuracy: 0.7598 - val_loss: 1.1458\n",
      "Epoch 21/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.7654 - loss: 1.1285 - val_accuracy: 0.7631 - val_loss: 1.1218\n",
      "Epoch 22/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 148ms/step - accuracy: 0.7644 - loss: 1.1170 - val_accuracy: 0.7663 - val_loss: 1.0941\n",
      "Epoch 23/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 145ms/step - accuracy: 0.7688 - loss: 1.0912 - val_accuracy: 0.7717 - val_loss: 1.0638\n",
      "Epoch 24/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.7739 - loss: 1.0617 - val_accuracy: 0.7764 - val_loss: 1.0420\n",
      "Epoch 25/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.7765 - loss: 1.0415 - val_accuracy: 0.7786 - val_loss: 1.0180\n",
      "Epoch 26/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.7832 - loss: 1.0057 - val_accuracy: 0.7847 - val_loss: 0.9910\n",
      "Epoch 27/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 145ms/step - accuracy: 0.7883 - loss: 0.9737 - val_accuracy: 0.7888 - val_loss: 0.9692\n",
      "Epoch 28/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 143ms/step - accuracy: 0.7860 - loss: 0.9803 - val_accuracy: 0.7947 - val_loss: 0.9417\n",
      "Epoch 29/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 145ms/step - accuracy: 0.7919 - loss: 0.9486 - val_accuracy: 0.7998 - val_loss: 0.9191\n",
      "Epoch 30/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 152ms/step - accuracy: 0.7961 - loss: 0.9285 - val_accuracy: 0.8044 - val_loss: 0.8972\n",
      "Epoch 31/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 154ms/step - accuracy: 0.8028 - loss: 0.8980 - val_accuracy: 0.8082 - val_loss: 0.8753\n",
      "Epoch 32/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 148ms/step - accuracy: 0.8089 - loss: 0.8610 - val_accuracy: 0.8120 - val_loss: 0.8522\n",
      "Epoch 33/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 155ms/step - accuracy: 0.8108 - loss: 0.8537 - val_accuracy: 0.8161 - val_loss: 0.8309\n",
      "Epoch 34/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 164ms/step - accuracy: 0.8182 - loss: 0.8213 - val_accuracy: 0.8210 - val_loss: 0.8117\n",
      "Epoch 35/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 156ms/step - accuracy: 0.8192 - loss: 0.8159 - val_accuracy: 0.8257 - val_loss: 0.7902\n",
      "Epoch 36/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 152ms/step - accuracy: 0.8231 - loss: 0.7947 - val_accuracy: 0.8270 - val_loss: 0.7707\n",
      "Epoch 37/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 153ms/step - accuracy: 0.8275 - loss: 0.7712 - val_accuracy: 0.8328 - val_loss: 0.7512\n",
      "Epoch 38/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.8316 - loss: 0.7513 - val_accuracy: 0.8386 - val_loss: 0.7321\n",
      "Epoch 39/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 155ms/step - accuracy: 0.8365 - loss: 0.7292 - val_accuracy: 0.8414 - val_loss: 0.7140\n",
      "Epoch 40/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 165ms/step - accuracy: 0.8383 - loss: 0.7204 - val_accuracy: 0.8438 - val_loss: 0.6959\n",
      "Epoch 41/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 153ms/step - accuracy: 0.8422 - loss: 0.6997 - val_accuracy: 0.8477 - val_loss: 0.6759\n",
      "Epoch 42/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 161ms/step - accuracy: 0.8476 - loss: 0.6755 - val_accuracy: 0.8524 - val_loss: 0.6578\n",
      "Epoch 43/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 162ms/step - accuracy: 0.8511 - loss: 0.6573 - val_accuracy: 0.8553 - val_loss: 0.6401\n",
      "Epoch 44/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.8544 - loss: 0.6406 - val_accuracy: 0.8616 - val_loss: 0.6223\n",
      "Epoch 45/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 160ms/step - accuracy: 0.8570 - loss: 0.6314 - val_accuracy: 0.8633 - val_loss: 0.6055\n",
      "Epoch 46/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 163ms/step - accuracy: 0.8634 - loss: 0.6006 - val_accuracy: 0.8696 - val_loss: 0.5870\n",
      "Epoch 47/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 156ms/step - accuracy: 0.8675 - loss: 0.5879 - val_accuracy: 0.8708 - val_loss: 0.5720\n",
      "Epoch 48/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 154ms/step - accuracy: 0.8692 - loss: 0.5722 - val_accuracy: 0.8751 - val_loss: 0.5525\n",
      "Epoch 49/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - accuracy: 0.8746 - loss: 0.5523 - val_accuracy: 0.8785 - val_loss: 0.5365\n",
      "Epoch 50/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 161ms/step - accuracy: 0.8779 - loss: 0.5388 - val_accuracy: 0.8843 - val_loss: 0.5192\n",
      "Epoch 51/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 153ms/step - accuracy: 0.8819 - loss: 0.5231 - val_accuracy: 0.8857 - val_loss: 0.5043\n",
      "Epoch 52/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 157ms/step - accuracy: 0.8835 - loss: 0.5132 - val_accuracy: 0.8899 - val_loss: 0.4879\n",
      "Epoch 53/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 163ms/step - accuracy: 0.8891 - loss: 0.4888 - val_accuracy: 0.8950 - val_loss: 0.4726\n",
      "Epoch 54/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 158ms/step - accuracy: 0.8925 - loss: 0.4716 - val_accuracy: 0.8971 - val_loss: 0.4580\n",
      "Epoch 55/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 169ms/step - accuracy: 0.8947 - loss: 0.4617 - val_accuracy: 0.8999 - val_loss: 0.4451\n",
      "Epoch 56/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 158ms/step - accuracy: 0.8993 - loss: 0.4435 - val_accuracy: 0.9042 - val_loss: 0.4331\n",
      "Epoch 57/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 166ms/step - accuracy: 0.9000 - loss: 0.4393 - val_accuracy: 0.9074 - val_loss: 0.4164\n",
      "Epoch 58/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 154ms/step - accuracy: 0.9057 - loss: 0.4190 - val_accuracy: 0.9098 - val_loss: 0.4047\n",
      "Epoch 59/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 155ms/step - accuracy: 0.9081 - loss: 0.4092 - val_accuracy: 0.9126 - val_loss: 0.3946\n",
      "Epoch 60/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 153ms/step - accuracy: 0.9115 - loss: 0.3970 - val_accuracy: 0.9157 - val_loss: 0.3783\n",
      "Epoch 61/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 148ms/step - accuracy: 0.9148 - loss: 0.3822 - val_accuracy: 0.9199 - val_loss: 0.3663\n",
      "Epoch 62/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 158ms/step - accuracy: 0.9169 - loss: 0.3713 - val_accuracy: 0.9234 - val_loss: 0.3549\n",
      "Epoch 63/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 148ms/step - accuracy: 0.9190 - loss: 0.3594 - val_accuracy: 0.9242 - val_loss: 0.3450\n",
      "Epoch 64/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 145ms/step - accuracy: 0.9223 - loss: 0.3486 - val_accuracy: 0.9258 - val_loss: 0.3338\n",
      "Epoch 65/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 146ms/step - accuracy: 0.9242 - loss: 0.3383 - val_accuracy: 0.9327 - val_loss: 0.3193\n",
      "Epoch 66/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 151ms/step - accuracy: 0.9281 - loss: 0.3234 - val_accuracy: 0.9343 - val_loss: 0.3093\n",
      "Epoch 67/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 153ms/step - accuracy: 0.9306 - loss: 0.3137 - val_accuracy: 0.9348 - val_loss: 0.3002\n",
      "Epoch 68/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 158ms/step - accuracy: 0.9332 - loss: 0.3041 - val_accuracy: 0.9394 - val_loss: 0.2887\n",
      "Epoch 69/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9353 - loss: 0.2965 - val_accuracy: 0.9407 - val_loss: 0.2791\n",
      "Epoch 70/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 153ms/step - accuracy: 0.9381 - loss: 0.2854 - val_accuracy: 0.9447 - val_loss: 0.2678\n",
      "Epoch 71/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 157ms/step - accuracy: 0.9410 - loss: 0.2721 - val_accuracy: 0.9444 - val_loss: 0.2592\n",
      "Epoch 72/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 151ms/step - accuracy: 0.9424 - loss: 0.2657 - val_accuracy: 0.9487 - val_loss: 0.2459\n",
      "Epoch 73/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 153ms/step - accuracy: 0.9446 - loss: 0.2540 - val_accuracy: 0.9492 - val_loss: 0.2422\n",
      "Epoch 74/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 146ms/step - accuracy: 0.9471 - loss: 0.2433 - val_accuracy: 0.9513 - val_loss: 0.2344\n",
      "Epoch 75/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.9497 - loss: 0.2380 - val_accuracy: 0.9526 - val_loss: 0.2261\n",
      "Epoch 76/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9512 - loss: 0.2304 - val_accuracy: 0.9566 - val_loss: 0.2131\n",
      "Epoch 77/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 149ms/step - accuracy: 0.9548 - loss: 0.2156 - val_accuracy: 0.9591 - val_loss: 0.2063\n",
      "Epoch 78/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 157ms/step - accuracy: 0.9559 - loss: 0.2106 - val_accuracy: 0.9609 - val_loss: 0.1966\n",
      "Epoch 79/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 159ms/step - accuracy: 0.9604 - loss: 0.1983 - val_accuracy: 0.9630 - val_loss: 0.1892\n",
      "Epoch 80/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 152ms/step - accuracy: 0.9614 - loss: 0.1904 - val_accuracy: 0.9636 - val_loss: 0.1822\n",
      "Epoch 81/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 152ms/step - accuracy: 0.9623 - loss: 0.1864 - val_accuracy: 0.9674 - val_loss: 0.1734\n",
      "Epoch 82/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.9644 - loss: 0.1772 - val_accuracy: 0.9691 - val_loss: 0.1649\n",
      "Epoch 83/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 143ms/step - accuracy: 0.9674 - loss: 0.1666 - val_accuracy: 0.9709 - val_loss: 0.1581\n",
      "Epoch 84/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 143ms/step - accuracy: 0.9686 - loss: 0.1608 - val_accuracy: 0.9734 - val_loss: 0.1515\n",
      "Epoch 85/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.9703 - loss: 0.1551 - val_accuracy: 0.9742 - val_loss: 0.1436\n",
      "Epoch 86/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 148ms/step - accuracy: 0.9722 - loss: 0.1485 - val_accuracy: 0.9758 - val_loss: 0.1385\n",
      "Epoch 87/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 145ms/step - accuracy: 0.9724 - loss: 0.1454 - val_accuracy: 0.9765 - val_loss: 0.1329\n",
      "Epoch 88/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 147ms/step - accuracy: 0.9749 - loss: 0.1366 - val_accuracy: 0.9774 - val_loss: 0.1313\n",
      "Epoch 89/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 152ms/step - accuracy: 0.9739 - loss: 0.1362 - val_accuracy: 0.9796 - val_loss: 0.1225\n",
      "Epoch 90/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 146ms/step - accuracy: 0.9774 - loss: 0.1278 - val_accuracy: 0.9805 - val_loss: 0.1168\n",
      "Epoch 91/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.9793 - loss: 0.1197 - val_accuracy: 0.9813 - val_loss: 0.1115\n",
      "Epoch 92/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.9803 - loss: 0.1162 - val_accuracy: 0.9830 - val_loss: 0.1089\n",
      "Epoch 93/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 143ms/step - accuracy: 0.9808 - loss: 0.1124 - val_accuracy: 0.9840 - val_loss: 0.1017\n",
      "Epoch 94/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 146ms/step - accuracy: 0.9825 - loss: 0.1050 - val_accuracy: 0.9864 - val_loss: 0.0944\n",
      "Epoch 95/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 145ms/step - accuracy: 0.9852 - loss: 0.0966 - val_accuracy: 0.9877 - val_loss: 0.0874\n",
      "Epoch 96/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 144ms/step - accuracy: 0.9861 - loss: 0.0897 - val_accuracy: 0.9890 - val_loss: 0.0851\n",
      "Epoch 97/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 145ms/step - accuracy: 0.9860 - loss: 0.0879 - val_accuracy: 0.9892 - val_loss: 0.0788\n",
      "Epoch 98/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 145ms/step - accuracy: 0.9877 - loss: 0.0819 - val_accuracy: 0.9901 - val_loss: 0.0746\n",
      "Epoch 99/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 146ms/step - accuracy: 0.9892 - loss: 0.0768 - val_accuracy: 0.9909 - val_loss: 0.0719\n",
      "Epoch 100/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 143ms/step - accuracy: 0.9894 - loss: 0.0728 - val_accuracy: 0.9908 - val_loss: 0.0708\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit([padded_train_encoder_inputs, padded_train_decoder_inputs],\n",
    "                    np.expand_dims(padded_train_decoder_targets, -1),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=([padded_val_encoder_inputs, padded_val_decoder_inputs],\n",
    "                                     np.expand_dims(padded_val_decoder_targets, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04267751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 38, 561,   4,  44,  39, 562,   6,   3,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 38, 174,  50,   4, 217,  28, 485,   4,   3,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 29, 175,   4,  23,  44,  19,   8, 105,   6,   3,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train_decoder_targets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72e1ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder inference model\n",
    "encoder_model = tf.keras.Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa0bf965",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = tf.keras.Input(shape=(hidden_dim,))\n",
    "decoder_state_input_c = tf.keras.Input(shape=(hidden_dim,))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_lstm_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_embedding, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
    "\n",
    "decoder_model = tf.keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8d52f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate an empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1)) # [[0]]\n",
    "    # Populate the first character of the target sequence with the start token.\n",
    "    target_seq[0, 0] = target_tokenizer.word_index['<sos>']\n",
    "\n",
    "    # Sampling loop\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :]) # (1, 1, 10556)\n",
    "        sampled_word = target_tokenizer.index_word.get(sampled_token_index, '<unk>')\n",
    "\n",
    "        if sampled_word == '<eos>' or len(decoded_sentence) > max_decoding_len:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_word\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    print(output_tokens.shape)\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b0e3820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "(1, 1, 2461)\n",
      "Input sentence: it's probably around somewhere . <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "Decoded sentence:  oh , that's easy .\n"
     ]
    }
   ],
   "source": [
    "# Test with a validation sentence\n",
    "test_input_seq = padded_val_encoder_inputs[0:1]  # Take the first sentence from validation set\n",
    "decoded_sentence = decode_sequence(test_input_seq)\n",
    "print('Input sentence:', ' '.join(source_tokenizer.sequences_to_texts(test_input_seq)))\n",
    "print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "44fab5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your sentence: how are you?\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "(1, 1, 2461)\n",
      "Input sentence: how are you?\n",
      "Decoded sentence:  you should take a break\n"
     ]
    }
   ],
   "source": [
    "input_sentence = input(\"Enter your sentence: \")\n",
    "\n",
    "input_sequence = source_tokenizer.texts_to_sequences([input_sentence])\n",
    "\n",
    "padded_input_sequence = pad_sequences(input_sequence, maxlen=32, padding='post')\n",
    "\n",
    "decoded_sentence = decode_sequence(padded_input_sequence)\n",
    "\n",
    "print('Input sentence:', input_sentence)\n",
    "print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b4f16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_without_attention(padded_source, encoder, target_tokenizer, decoder):\n",
    "    # Your translation logic here, for example:\n",
    "    states_value = encoder.predict(padded_source)\n",
    "\n",
    "    # Start decoding process\n",
    "    target_seq = np.zeros((1, 1))  # Initial target sequence\n",
    "    target_seq[0, 0] = target_tokenizer.word_index['<sos>']  # Assuming <sos> is the start token\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder.predict([target_seq] + [states_value])\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = target_tokenizer.index_word.get(sampled_token_index, '<unk>')\n",
    "\n",
    "        if sampled_word == '<eos>' or len(decoded_sentence) > max_decoding_len:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_word\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence  # Return the decoded sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7dd893e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['golf is a silly game.\\tit certainly is.',\n",
       " 'i got a dent in the parking lot.\\thow did you get it?',\n",
       " 'what is your favorite kind of music?\\ti listen to various types of music.',\n",
       " 'they forget where they came from.\\tmaybe you should run for office.',\n",
       " \"thank you very much, that's kind of you.\\tdon't mention it.\",\n",
       " 'did you take pictures at the world war ii monument?\\toh, yes. we all took lots of pictures.',\n",
       " \"really, where did you get it?\\ti got it from macy's.\",\n",
       " \"yes. that's why it's also the best hamburger in town.\\ta great burger and great service.\",\n",
       " \"a good gun costs $400 or more.\\twell, if you bring your receipt, maybe they'll give you $400.\",\n",
       " \"a lot, like the party i'm having on friday.\\twell, that's cool.\",\n",
       " \"i bought three pounds of potatoes for a dollar.\\tthat's a good deal.\",\n",
       " 'why do you want to move there?\\tbecause i want to make a lot of money.',\n",
       " \"no one at work likes him.\\tcan't you report him to his supervisor?\",\n",
       " \"who were you writing to?\\tit's to my mom.\",\n",
       " \"i don't know.\\tit's better to be pale than to have skin cancer.\"]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random.seed is just here to re-create results.\n",
    "random.seed(1)\n",
    "sentences = random.sample(val, 15)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cf9156f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def translate_sentences(sentences, translation_func, source_tokenizer, encoder,\n",
    "                        target_tokenizer, decoder, max_encoder_seq_length):\n",
    "    translations = {'Tokenized Original': [], 'Reference': [], 'Translation': []}\n",
    "\n",
    "    for s in sentences:\n",
    "        # Split the input into source and target sentences\n",
    "        source, target = s.split(Separator)\n",
    "\n",
    "        # Preprocess the source sentence\n",
    "        source = preprocess_sentence(source)\n",
    "\n",
    "        # Tokenize the source sentence\n",
    "        tokenized_sentence = source_tokenizer.texts_to_sequences([source])[0]  # Convert to sequence\n",
    "\n",
    "        # Pad the tokenized sentence to the maximum length\n",
    "        padded_source = pad_sequences([tokenized_sentence], maxlen=max_encoder_seq_length, padding='post')\n",
    "\n",
    "        # Call the translation function to get the translation\n",
    "        translated = translation_func(padded_source, encoder, target_tokenizer, decoder)\n",
    "\n",
    "        # Store the results in the dictionary\n",
    "        translations['Tokenized Original'].append(tokenized_sentence)\n",
    "        translations['Reference'].append(target)\n",
    "        translations['Translation'].append(translated)\n",
    "\n",
    "    return translations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7611dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    }
   ],
   "source": [
    "# Example definition of max_encoder_seq_length\n",
    "max_encoder_seq_length = 30  # Adjust this value based on your model's configuration\n",
    "\n",
    "# Now call translate_sentences with the required parameters\n",
    "translations_no_attention = pd.DataFrame(translate_sentences(\n",
    "    sentences,\n",
    "    translate_without_attention,\n",
    "    source_tokenizer,\n",
    "    encoder_model,\n",
    "    target_tokenizer,\n",
    "    decoder_model,  # Ensure decoder is passed correctly\n",
    "    max_encoder_seq_length  # Pass the max length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf2092a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # No masking here. We'll handle it ourselves.\n",
    "        self.embedding = layers.Embedding(source_vocab_size,\n",
    "                                          embedding_dim,\n",
    "                                          name='encoder_embedding_layer')\n",
    "\n",
    "        # return_sequences is set to True this time.\n",
    "        self.lstm = layers.LSTM(hidden_dim,\n",
    "                                return_sequences=True,\n",
    "                                return_state=True,\n",
    "                                name='encoder_lstm')\n",
    "\n",
    "    def call(self, input):\n",
    "        embeddings = self.embedding(input)\n",
    "\n",
    "        # output_seq will hold the encoder's hidden states from each time step.\n",
    "        output_seq, state_h, state_c = self.lstm(embeddings)\n",
    "\n",
    "        return output_seq, state_h, state_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee452ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoder = Encoder(source_vocab_size, embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0aca455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 22)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1016,    6,   40,   18,    5,  160,    3,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  29,  640,    2,   40,   37,  548,    3,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  29,  152,   48,    2,  290,   28,  486,    2,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_encoder_batch = padded_train_encoder_inputs[:3]\n",
    "print(test_encoder_batch.shape)\n",
    "test_encoder_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "653b2f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoder_outputs, state_h, state_c = test_encoder(test_encoder_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2c546d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 22, 256)\n",
      "(3, 256)\n",
      "(3, 256)\n"
     ]
    }
   ],
   "source": [
    "print(test_encoder_outputs.shape)\n",
    "print(state_h.shape)\n",
    "print(state_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "669abd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttention(tf.keras.Model):\n",
    "  def __init__(self, hidden_dim):\n",
    "    super(LuongAttention, self).__init__()\n",
    "\n",
    "    self.w = layers.Dense(hidden_dim, name='encoder_outputs_dense')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    encoder_output_seq, decoder_output = inputs\n",
    "    z = self.w(encoder_output_seq)\n",
    "    attention_scores = tf.matmul(decoder_output, z, transpose_b=True)\n",
    "    attention_weights = tf.keras.activations.softmax(attention_scores, axis=-1)\n",
    "    context = tf.matmul(attention_weights, encoder_output_seq)\n",
    "\n",
    "    return attention_weights, context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b83f5821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.embedding_layer = layers.Embedding(vocab_size,\n",
    "                                            embedding_dim,\n",
    "                                            name='decoder_embedding_layer')\n",
    "\n",
    "    self.lstm = layers.LSTM(hidden_dim,\n",
    "                            return_sequences=True,\n",
    "                            return_state=True,\n",
    "                            name='decoder_lstm')\n",
    "\n",
    "    self.attention = LuongAttention(hidden_dim)\n",
    "\n",
    "    self.w = tf.keras.layers.Dense(hidden_dim, activation='tanh', name='attended_outputs_dense')\n",
    "\n",
    "    self.dense = layers.Dense(vocab_size, name='decoder_dense')\n",
    "\n",
    "\n",
    "  def call(self, inputs):\n",
    "    decoder_input, encoder_output_seq, lstm_state = inputs\n",
    "    embeddings = self.embedding_layer(decoder_input)\n",
    "\n",
    "    decoder_output, state_h, state_c = self.lstm(embeddings, initial_state=lstm_state)\n",
    "\n",
    "    weights, context = self.attention([encoder_output_seq, decoder_output])\n",
    "\n",
    "    decoder_output_with_attention = self.w(tf.concat(\n",
    "        [tf.squeeze(context, 1), tf.squeeze(decoder_output, 1)], -1))\n",
    "\n",
    "    logits = self.dense(decoder_output_with_attention)\n",
    "\n",
    "    return logits, state_h, state_c, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cc08644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_decoder = Decoder(target_vocab_size, embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0d014388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2,  38, 561,   4,  44,  39, 562,   6,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  2,  38, 174,  50,   4, 217,  28, 485,   4,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  2,  29, 175,   4,  23,  44,  19,   8, 105,   6,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_decoder_batch = padded_train_decoder_inputs[:3]\n",
    "print(test_decoder_batch.shape)\n",
    "test_decoder_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "40e0cc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38, 38, 29])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_decoder_batch[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "340b97f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=int32, numpy=\n",
       "array([[38],\n",
       "       [38],\n",
       "       [29]])>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_decoder_inputs = tf.expand_dims(test_decoder_batch[:, 1], 1)\n",
    "next_decoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bedd45c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial values for state_h and state_c are from the encoder.\n",
    "test_decoder_logits, state_h, state_c, test_decoder_weights = test_decoder(\n",
    "    [\n",
    "      next_decoder_inputs,\n",
    "      test_encoder_outputs,\n",
    "      [state_h, state_c]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34db662e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2461)\n",
      "(3, 1, 22)\n"
     ]
    }
   ],
   "source": [
    "print(test_decoder_logits.shape)\n",
    "print(test_decoder_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0065fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(targets, logits):\n",
    "  ce_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "  mask = tf.cast(tf.math.not_equal(targets, 0), tf.float32)\n",
    "\n",
    "  return ce_loss(targets, logits, sample_weight=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5a77ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((padded_train_encoder_inputs,\n",
    "                                              padded_train_decoder_inputs,\n",
    "                                              padded_train_decoder_targets)).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7cda5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslatorTrainer(tf.keras.Model):\n",
    "  def __init__(self, encoder, decoder):\n",
    "    super(TranslatorTrainer, self).__init__()\n",
    "\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "\n",
    "  # This method will be called by model.fit for each batch.\n",
    "  @tf.function\n",
    "  def train_step(self, inputs):\n",
    "      loss = 0.\n",
    "\n",
    "      encoder_input_seq, decoder_input_seq, decoder_target_seq = inputs\n",
    "\n",
    "      with tf.GradientTape() as tape:\n",
    "          encoder_output_seq, state_h, state_c = self.encoder(encoder_input_seq)\n",
    "\n",
    "          # We need to create a loop to iterate through the target sequences\n",
    "          for i in range(decoder_target_seq.shape[1]):\n",
    "\n",
    "              # Input to the decoder must have shape of (batch_size, length)\n",
    "              # so we need to expand one dimension (just like in the previous example).\n",
    "              next_decoder_input = tf.expand_dims(decoder_input_seq[:, i], 1)\n",
    "              logits, state_h, state_c, _ = self.decoder(\n",
    "                  [next_decoder_input, encoder_output_seq, (state_h, state_c)])\n",
    "\n",
    "              # The loss is now accumulated through the whole batch\n",
    "              loss += self.loss(decoder_target_seq[:, i], logits)\n",
    "\n",
    "      # Update the parameters and the optimizer\n",
    "      variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "      gradients = tape.gradient(loss, variables)\n",
    "      self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "      return {'loss': loss / decoder_target_seq.shape[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1d9ce05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(source_vocab_size, embedding_dim, hidden_dim)\n",
    "decoder = Decoder(target_vocab_size, embedding_dim, hidden_dim)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "translator_trainer = TranslatorTrainer(encoder, decoder)\n",
    "translator_trainer.compile(optimizer=optimizer, loss=loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a0bbb0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 258ms/step - loss: 2.1550\n",
      "Epoch 2/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 260ms/step - loss: 1.8967\n",
      "Epoch 3/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 253ms/step - loss: 1.7858\n",
      "Epoch 4/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 258ms/step - loss: 1.7040\n",
      "Epoch 5/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 254ms/step - loss: 1.6401\n",
      "Epoch 6/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 256ms/step - loss: 1.5792\n",
      "Epoch 7/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 253ms/step - loss: 1.5204\n",
      "Epoch 8/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 258ms/step - loss: 1.4674\n",
      "Epoch 9/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 288ms/step - loss: 1.4230\n",
      "Epoch 10/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 270ms/step - loss: 1.3816\n",
      "Epoch 11/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 249ms/step - loss: 1.3448\n",
      "Epoch 12/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 252ms/step - loss: 1.3147\n",
      "Epoch 13/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 250ms/step - loss: 1.2855\n",
      "Epoch 14/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 249ms/step - loss: 1.2505\n",
      "Epoch 15/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 258ms/step - loss: 1.2129\n",
      "Epoch 16/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 257ms/step - loss: 1.1845\n",
      "Epoch 17/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 256ms/step - loss: 1.1552\n",
      "Epoch 18/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 256ms/step - loss: 1.1249\n",
      "Epoch 19/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 253ms/step - loss: 1.0905\n",
      "Epoch 20/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 254ms/step - loss: 1.0597\n",
      "Epoch 21/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 253ms/step - loss: 1.0327\n",
      "Epoch 22/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 252ms/step - loss: 1.0058\n",
      "Epoch 23/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 255ms/step - loss: 0.9759\n",
      "Epoch 24/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 253ms/step - loss: 0.9490\n",
      "Epoch 25/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 254ms/step - loss: 0.9178\n",
      "Epoch 26/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 254ms/step - loss: 0.8909\n",
      "Epoch 27/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 254ms/step - loss: 0.8650\n",
      "Epoch 28/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 256ms/step - loss: 0.8395\n",
      "Epoch 29/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 254ms/step - loss: 0.8147\n",
      "Epoch 30/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 253ms/step - loss: 0.7920\n",
      "Epoch 31/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 257ms/step - loss: 0.7726\n",
      "Epoch 32/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 255ms/step - loss: 0.7535\n",
      "Epoch 33/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 254ms/step - loss: 0.7247\n",
      "Epoch 34/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 253ms/step - loss: 0.6984\n",
      "Epoch 35/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 261ms/step - loss: 0.6672\n",
      "Epoch 36/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 253ms/step - loss: 0.6421\n",
      "Epoch 37/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 253ms/step - loss: 0.6133\n",
      "Epoch 38/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 257ms/step - loss: 0.5831\n",
      "Epoch 39/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 255ms/step - loss: 0.5532\n",
      "Epoch 40/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 254ms/step - loss: 0.5267\n",
      "Epoch 41/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 255ms/step - loss: 0.4963\n",
      "Epoch 42/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 256ms/step - loss: 0.4643\n",
      "Epoch 43/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 255ms/step - loss: 0.4371\n",
      "Epoch 44/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 254ms/step - loss: 0.4023\n",
      "Epoch 45/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 254ms/step - loss: 0.3742\n",
      "Epoch 46/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 256ms/step - loss: 0.3493\n",
      "Epoch 47/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 256ms/step - loss: 0.3259\n",
      "Epoch 48/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 255ms/step - loss: 0.2999\n",
      "Epoch 49/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 254ms/step - loss: 0.2770\n",
      "Epoch 50/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 253ms/step - loss: 0.2564\n",
      "Epoch 51/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 254ms/step - loss: 0.2339\n",
      "Epoch 52/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 258ms/step - loss: 0.2159\n",
      "Epoch 53/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 259ms/step - loss: 0.1988\n",
      "Epoch 54/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 259ms/step - loss: 0.1825\n",
      "Epoch 55/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 260ms/step - loss: 0.1696\n",
      "Epoch 56/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 259ms/step - loss: 0.1577\n",
      "Epoch 57/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 258ms/step - loss: 0.1424\n",
      "Epoch 58/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 261ms/step - loss: 0.1297\n",
      "Epoch 59/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 260ms/step - loss: 0.1194\n",
      "Epoch 60/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 259ms/step - loss: 0.1112\n",
      "Epoch 61/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 273ms/step - loss: 0.1032\n",
      "Epoch 62/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 258ms/step - loss: 0.0957\n",
      "Epoch 63/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 259ms/step - loss: 0.0867\n",
      "Epoch 64/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 260ms/step - loss: 0.0869\n",
      "Epoch 65/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 257ms/step - loss: 0.0803\n",
      "Epoch 66/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 257ms/step - loss: 0.0701\n",
      "Epoch 67/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 258ms/step - loss: 0.0634\n",
      "Epoch 68/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 259ms/step - loss: 0.0580\n",
      "Epoch 69/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 258ms/step - loss: 0.0534\n",
      "Epoch 70/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 258ms/step - loss: 0.0516\n",
      "Epoch 71/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 261ms/step - loss: 0.0469\n",
      "Epoch 72/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 259ms/step - loss: 0.0428\n",
      "Epoch 73/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 259ms/step - loss: 0.0376\n",
      "Epoch 74/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 258ms/step - loss: 0.0337\n",
      "Epoch 75/75\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 277ms/step - loss: 0.0307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x209a3beff10>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 75\n",
    "translator_trainer.fit(dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "27d0717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save_weights('attention_encoder.weights.h5')\n",
    "decoder.save_weights('attention_decoder.weights.h5')\n",
    "\n",
    "# !zip -r ./attention_weights.zip ./attention_encoder.weights.h5 ./attention_decoder.weights.h5\n",
    "\n",
    "# files.download('./attention_weights.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "54727e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_with_attention(padded_source, encoder, target_tokenizer, decoder, max_translated_len=30):\n",
    "    # Prediction logic\n",
    "    encoder_output, state_h, state_c = encoder.predict(padded_source)\n",
    "\n",
    "    current_word = '<sos>'\n",
    "    decoded_sentence = []\n",
    "\n",
    "    while len(decoded_sentence) < max_translated_len:\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = target_tokenizer.word_index[current_word]\n",
    "\n",
    "        logits, state_h, state_c, _ = decoder.predict([target_seq, encoder_output, (state_h, state_c)])\n",
    "        current_token_index = np.argmax(logits[0])\n",
    "        current_word = target_tokenizer.index_word.get(current_token_index, '')\n",
    "\n",
    "        if current_word == '<eos>':\n",
    "            break\n",
    "\n",
    "        decoded_sentence.append(current_word)\n",
    "\n",
    "    return ' '.join(decoded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "13fa8120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    }
   ],
   "source": [
    "# Example definition of max_encoder_seq_length\n",
    "max_encoder_seq_length = 30  # Adjust this value based on your model's configuration\n",
    "\n",
    "# Now call translate_sentences with the required parameters\n",
    "shorter_translations_w_attention = pd.DataFrame(translate_sentences(\n",
    "    sentences,\n",
    "    translate_with_attention,\n",
    "    source_tokenizer,\n",
    "    encoder,\n",
    "    target_tokenizer,\n",
    "    decoder,  # Ensure decoder is passed correctly\n",
    "    max_encoder_seq_length  # Pass the max length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c94c7226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    }
   ],
   "source": [
    "max_decoder_seq_length = 30\n",
    "\n",
    "shorter_translations_w_attention = pd.DataFrame(translate_sentences(sentences, translate_with_attention,\n",
    "                                                                    source_tokenizer, encoder,\n",
    "                                                                    target_tokenizer, decoder,\n",
    "                                                                    max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4fb97d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokenized Original</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Translation W/ Attention</th>\n",
       "      <th>Translation W/O Attention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[627, 14, 9, 1315, 171, 2]</td>\n",
       "      <td>it certainly is.</td>\n",
       "      <td>it certainly is .</td>\n",
       "      <td>it was seven feet tall .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4, 90, 9, 1857, 19, 7, 615, 87, 2]</td>\n",
       "      <td>how did you get it?</td>\n",
       "      <td>how did you get it ?</td>\n",
       "      <td>how did you get it ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[13, 14, 42, 277, 212, 15, 401, 3]</td>\n",
       "      <td>i listen to various types of music.</td>\n",
       "      <td>i listen to various types of music .</td>\n",
       "      <td>i like not to .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[24, 601, 122, 24, 366, 120, 2]</td>\n",
       "      <td>maybe you should run for office.</td>\n",
       "      <td>maybe you should run for office .</td>\n",
       "      <td>maybe you should see you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[153, 5, 138, 89, 6, 38, 212, 15, 5, 2]</td>\n",
       "      <td>don't mention it.</td>\n",
       "      <td>don't mention it .</td>\n",
       "      <td>i know , you should really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[20, 5, 115, 1375, 54, 7, 173, 633, 759, 1374, 3]</td>\n",
       "      <td>oh, yes. we all took lots of pictures.</td>\n",
       "      <td>oh , yes . we all took lots of pictures .</td>\n",
       "      <td>oh , yes . we all took lots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[51, 6, 122, 20, 5, 56, 10, 3]</td>\n",
       "      <td>i got it from macy's.</td>\n",
       "      <td>i got it from macy's .</td>\n",
       "      <td>i don't know which one i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[30, 2, 38, 43, 22, 447, 7, 194, 916, 19, 937, 2]</td>\n",
       "      <td>a great burger and great service.</td>\n",
       "      <td>a great burger and great service .</td>\n",
       "      <td>a great burger and great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[9, 48, 631, 414, 1351, 95, 123, 2]</td>\n",
       "      <td>well, if you bring your receipt, maybe they'll...</td>\n",
       "      <td>well , if you bring your receipt , maybe they'...</td>\n",
       "      <td>well , if you bring your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[9, 87, 6, 23, 7, 165, 29, 338, 35, 226, 2]</td>\n",
       "      <td>well, that's cool.</td>\n",
       "      <td>well , that's cool .</td>\n",
       "      <td>well , that's cool .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[4, 224, 280, 304, 15, 544, 28, 9, 453, 2]</td>\n",
       "      <td>that's a good deal.</td>\n",
       "      <td>that's a good deal .</td>\n",
       "      <td>that's a good deal .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[43, 12, 5, 50, 8, 751, 58, 3]</td>\n",
       "      <td>because i want to make a lot of money.</td>\n",
       "      <td>because i want to make a lot of money .</td>\n",
       "      <td>because i want to make a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[33, 59, 54, 180, 511, 83, 2]</td>\n",
       "      <td>can't you report him to his supervisor?</td>\n",
       "      <td>can't you report him to his supervisor ?</td>\n",
       "      <td>can't you report him to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[117, 121, 5, 902, 8, 3]</td>\n",
       "      <td>it's to my mom.</td>\n",
       "      <td>it's to my mom .</td>\n",
       "      <td>it's to my mom . i don't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[4, 27, 52, 2]</td>\n",
       "      <td>it's better to be pale than to have skin cancer.</td>\n",
       "      <td>it's better to be pale than to have skin cancer .</td>\n",
       "      <td>it's better to be pale than</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Tokenized Original  \\\n",
       "0                          [627, 14, 9, 1315, 171, 2]   \n",
       "1                 [4, 90, 9, 1857, 19, 7, 615, 87, 2]   \n",
       "2                  [13, 14, 42, 277, 212, 15, 401, 3]   \n",
       "3                     [24, 601, 122, 24, 366, 120, 2]   \n",
       "4             [153, 5, 138, 89, 6, 38, 212, 15, 5, 2]   \n",
       "5   [20, 5, 115, 1375, 54, 7, 173, 633, 759, 1374, 3]   \n",
       "6                      [51, 6, 122, 20, 5, 56, 10, 3]   \n",
       "7   [30, 2, 38, 43, 22, 447, 7, 194, 916, 19, 937, 2]   \n",
       "8                 [9, 48, 631, 414, 1351, 95, 123, 2]   \n",
       "9         [9, 87, 6, 23, 7, 165, 29, 338, 35, 226, 2]   \n",
       "10         [4, 224, 280, 304, 15, 544, 28, 9, 453, 2]   \n",
       "11                     [43, 12, 5, 50, 8, 751, 58, 3]   \n",
       "12                      [33, 59, 54, 180, 511, 83, 2]   \n",
       "13                           [117, 121, 5, 902, 8, 3]   \n",
       "14                                     [4, 27, 52, 2]   \n",
       "\n",
       "                                            Reference  \\\n",
       "0                                    it certainly is.   \n",
       "1                                 how did you get it?   \n",
       "2                 i listen to various types of music.   \n",
       "3                    maybe you should run for office.   \n",
       "4                                   don't mention it.   \n",
       "5              oh, yes. we all took lots of pictures.   \n",
       "6                               i got it from macy's.   \n",
       "7                   a great burger and great service.   \n",
       "8   well, if you bring your receipt, maybe they'll...   \n",
       "9                                  well, that's cool.   \n",
       "10                                that's a good deal.   \n",
       "11             because i want to make a lot of money.   \n",
       "12            can't you report him to his supervisor?   \n",
       "13                                    it's to my mom.   \n",
       "14   it's better to be pale than to have skin cancer.   \n",
       "\n",
       "                             Translation W/ Attention  \\\n",
       "0                                   it certainly is .   \n",
       "1                                how did you get it ?   \n",
       "2                i listen to various types of music .   \n",
       "3                   maybe you should run for office .   \n",
       "4                                  don't mention it .   \n",
       "5           oh , yes . we all took lots of pictures .   \n",
       "6                              i got it from macy's .   \n",
       "7                  a great burger and great service .   \n",
       "8   well , if you bring your receipt , maybe they'...   \n",
       "9                                well , that's cool .   \n",
       "10                               that's a good deal .   \n",
       "11            because i want to make a lot of money .   \n",
       "12           can't you report him to his supervisor ?   \n",
       "13                                   it's to my mom .   \n",
       "14  it's better to be pale than to have skin cancer .   \n",
       "\n",
       "       Translation W/O Attention  \n",
       "0       it was seven feet tall .  \n",
       "1           how did you get it ?  \n",
       "2                i like not to .  \n",
       "3       maybe you should see you  \n",
       "4     i know , you should really  \n",
       "5    oh , yes . we all took lots  \n",
       "6       i don't know which one i  \n",
       "7       a great burger and great  \n",
       "8       well , if you bring your  \n",
       "9           well , that's cool .  \n",
       "10          that's a good deal .  \n",
       "11      because i want to make a  \n",
       "12       can't you report him to  \n",
       "13      it's to my mom . i don't  \n",
       "14   it's better to be pale than  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorter_translations_w_attention.rename(columns={'Translation': 'Translation W/ Attention'}, inplace=True)\n",
    "shorter_translations_w_attention['Translation W/O Attention'] = translations_no_attention['Translation']\n",
    "shorter_translations_w_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3851e684",
   "metadata": {},
   "source": [
    "While attention mechanisms have significantly improved natural language processing tasks, their effectiveness can be limited when trained on smaller datasets. For building a truly functional and reliable chatbot, it's essential to fine-tune a model that has been pre-trained on a vast amount of diverse data. Models like BERT, GPT, or LLaMA offer robust understanding and generation capabilities, making them ideal candidates for this purpose. By leveraging their extensive training, these models can better comprehend a wide range of inputs and contexts, resulting in more accurate and relevant responses in conversational applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6addf471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he sank a 20-foot putt on the last hole to win by one stroke!\\the sank a 25-footer last year at the same tournament to win by one stroke.',\n",
       " \"you're not going to examine it before we order dinner?\\tno, i'd rather not find out that it's dirty, because i'm pretty hungry right now.\",\n",
       " \"i like the one where the fireman tells us why we should vote yes.\\tdon't believe him! whatever the tv ads tell you, the opposite is true.\",\n",
       " \"i couldn't keep from laughing throughout the whole movie.\\ti was laughing hysterically the whole time; my stomach muscles hurt afterwards.\",\n",
       " \"you don't need a good nose for thatÃâcigarettes stink.\\tbut when i sneak just one cigarette in the morning, she can smell it that evening!\",\n",
       " 'bluedog123 is just the street. you have to give me the city, state, and zip code.\\toh, i get it. my email address is bluedog123@yahoo.com.',\n",
       " \"considering that it's over ninety degrees outside, that would be weird.\\texactly, it wouldn't be nice if it started raining. it's too hot.\",\n",
       " 'the husband of the driver who ran over two college students at 3 a.m.\\toh, yeah. the girl died instantly, and the boy is still in the hospital.',\n",
       " \"when you're inside, you will always hear cars stopping and stopping at the intersection.\\tor you'll hear the collision if someone doesn't stop.\",\n",
       " \"i mean, someone used their dirty hands to pick the bananas, the apples, and the oranges.\\twell, you better save a wipe for the dirty dollar bills you're going to pay with.\"]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = train.copy()\n",
    "pairs.sort(key=lambda s: len(s))\n",
    "longer_sentences = pairs[-10:]\n",
    "longer_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ff382f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your sentence: good luck with school\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Input sentence: good luck with school\n",
      "Chatbot response: thank you very much .\n"
     ]
    }
   ],
   "source": [
    "def chatbot_response(input_sentence, source_tokenizer, encoder, target_tokenizer, decoder, max_encoder_seq_length=32):\n",
    "  input_sequence = source_tokenizer.texts_to_sequences([input_sentence])\n",
    "  padded_input_sequence = pad_sequences(input_sequence, maxlen=max_encoder_seq_length, padding='post')\n",
    "  decoded_sentence = translate_with_attention(padded_input_sequence, encoder, target_tokenizer, decoder)\n",
    "\n",
    "  return decoded_sentence\n",
    "\n",
    "input_sentence = input(\"Enter your sentence: \")\n",
    "response = chatbot_response(input_sentence, source_tokenizer, encoder, target_tokenizer, decoder)\n",
    "print('Input sentence:', input_sentence)\n",
    "print('Chatbot response:', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0cc63c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
